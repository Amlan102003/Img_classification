{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-16T13:29:12.012468Z","iopub.execute_input":"2023-07-16T13:29:12.012847Z","iopub.status.idle":"2023-07-16T13:29:12.019900Z","shell.execute_reply.started":"2023-07-16T13:29:12.012817Z","shell.execute_reply":"2023-07-16T13:29:12.018795Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom matplotlib import pyplot\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:29:12.274575Z","iopub.execute_input":"2023-07-16T13:29:12.274942Z","iopub.status.idle":"2023-07-16T13:29:12.281049Z","shell.execute_reply.started":"2023-07-16T13:29:12.274898Z","shell.execute_reply":"2023-07-16T13:29:12.279974Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def load_dataset():\n    (trainX, trainY),(testX, testY)= cifar10.load_data()\n    trainY=to_categorical(trainY)\n    testY= to_categorical(testY)\n    return trainX, trainY, testX, testY\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:29:12.283813Z","iopub.execute_input":"2023-07-16T13:29:12.284650Z","iopub.status.idle":"2023-07-16T13:29:12.294712Z","shell.execute_reply.started":"2023-07-16T13:29:12.284613Z","shell.execute_reply":"2023-07-16T13:29:12.293522Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Function to scale pixels \ndef prep_pixels(train, test):\n    #convert from integers to floats\n    train_norm=train.astype('float32')\n    test_norm=test.astype('float32')\n    #Normalize to range 0-1\n    train_norm=train_norm/255.0\n    test_norm=test_norm/255.0\n    return train_norm, test_norm\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:29:12.296847Z","iopub.execute_input":"2023-07-16T13:29:12.297160Z","iopub.status.idle":"2023-07-16T13:29:12.306082Z","shell.execute_reply.started":"2023-07-16T13:29:12.297136Z","shell.execute_reply":"2023-07-16T13:29:12.304943Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def define_model():\n    model=Sequential()\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.4))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax'))\n    opt=SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'] )\n    return model\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:29:12.307246Z","iopub.execute_input":"2023-07-16T13:29:12.307546Z","iopub.status.idle":"2023-07-16T13:29:12.323371Z","shell.execute_reply.started":"2023-07-16T13:29:12.307515Z","shell.execute_reply":"2023-07-16T13:29:12.322198Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\ndef summarize_diagnostics(history):\n    pyplot.subplot(211)\n    pyplot.title('Cross entropy Loss')\n    pyplot.plot(history.history['loss'], color='blue', label='train')\n    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n    saved_file= sys.argv[0].split('/')[-1]\n    pyplot.savefig(saved_file + '_plot.png')\n    pyplot.close()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:29:12.326446Z","iopub.execute_input":"2023-07-16T13:29:12.327041Z","iopub.status.idle":"2023-07-16T13:29:12.338427Z","shell.execute_reply.started":"2023-07-16T13:29:12.327007Z","shell.execute_reply":"2023-07-16T13:29:12.337446Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def run_test_harness():\n    trainX, trainY, testX, testY= load_dataset()\n    trainX, testX=prep_pixels(trainX, testX)\n    model=define_model()\n    datagen=ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n    IT_Train= datagen.flow(trainX, trainY, batch_size=64)\n    Steps= int(trainX.shape[0]/64)\n    history=model.fit_generator(IT_Train, steps_per_epoch=Steps,epochs=100, validation_data=(testX, testY), verbose=0)\n    _, acc=model.evaluate(testX, testY, verbose=0)\n    \n    print('> %.3f' % (acc * 100.0))\n    summarize_diagnostics(history)\n    \n    \n    \n    \nrun_test_harness()\n    \n        \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:29:12.341744Z","iopub.execute_input":"2023-07-16T13:29:12.342081Z","iopub.status.idle":"2023-07-16T14:27:10.458172Z","shell.execute_reply.started":"2023-07-16T13:29:12.342055Z","shell.execute_reply":"2023-07-16T14:27:10.457136Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_29/990079124.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  history=model.fit_generator(IT_Train, steps_per_epoch=Steps,epochs=100, validation_data=(testX, testY), verbose=0)\n2023-07-16 13:29:14.719978: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"> 79.010\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}